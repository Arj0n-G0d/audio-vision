{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T16:11:57.247295Z",
     "iopub.status.busy": "2025-02-07T16:11:57.247024Z",
     "iopub.status.idle": "2025-02-07T16:12:01.784832Z",
     "shell.execute_reply": "2025-02-07T16:12:01.783696Z",
     "shell.execute_reply.started": "2025-02-07T16:11:57.247274Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install noisereduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Of Content\n",
    "1. Preprocessing the dataset\n",
    "2. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reducing noise from the audio files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T16:12:01.786568Z",
     "iopub.status.busy": "2025-02-07T16:12:01.786254Z",
     "iopub.status.idle": "2025-02-07T16:18:53.801750Z",
     "shell.execute_reply": "2025-02-07T16:18:53.800810Z",
     "shell.execute_reply.started": "2025-02-07T16:12:01.786545Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm  #for progress bar\n",
    "\n",
    "# Defining input and output directories\n",
    "input_dir = \"/kaggle/input/ravdess-emotional-speech-audio\" \n",
    "output_dir = \"/kaggle/working/denoised_ravdess_audio\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Processing each subfolder and file in the dataset\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    \n",
    "    relative_path = os.path.relpath(root, input_dir)\n",
    "    output_folder = os.path.join(output_dir, relative_path)\n",
    "    os.makedirs(output_folder, exist_ok=True) \n",
    "\n",
    "    for file in tqdm(files, desc=f\"Processing {relative_path}\"):\n",
    "        if file.endswith(\".wav\"):\n",
    "            input_file_path = os.path.join(root, file)\n",
    "            output_file_path = os.path.join(output_folder, file)\n",
    "\n",
    "            try:\n",
    "                \n",
    "                y, sr = librosa.load(input_file_path, sr=None)\n",
    "\n",
    "                \n",
    "                noise_start = 0\n",
    "                noise_end = int(sr * 0.5) \n",
    "                noise_profile = y[noise_start:noise_end]\n",
    "\n",
    "                \n",
    "                y_denoised = nr.reduce_noise(y=y, sr=sr, y_noise=noise_profile)\n",
    "\n",
    "                \n",
    "                sf.write(output_file_path, y_denoised, sr)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_file_path}: {e}\")\n",
    "\n",
    "print(f\"✅ Noise reduction complete! Denoised files are saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating mel spectograms of the corresponding audio files in greyscale and applying noise masking and then resizing the spectograms into size of 224*224 inorder to be sent as input to the resNet50 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T16:18:53.803308Z",
     "iopub.status.busy": "2025-02-07T16:18:53.802922Z",
     "iopub.status.idle": "2025-02-07T16:22:39.710787Z",
     "shell.execute_reply": "2025-02-07T16:22:39.709957Z",
     "shell.execute_reply.started": "2025-02-07T16:18:53.803286Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "input_dir = \"/kaggle/working/denoised_ravdess_audio\"  \n",
    "output_dir = \"/kaggle/working/spectrograms\"\n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to apply noise masking\n",
    "def apply_mask(spectrogram_db):\n",
    "    threshold = np.percentile(spectrogram_db, 5)  \n",
    "    spectrogram_db[spectrogram_db < threshold] = np.min(spectrogram_db)\n",
    "    return spectrogram_db\n",
    "\n",
    "print(\"Started processing audio files...\")\n",
    "\n",
    "# Iterating through each actor's folder\n",
    "for actor_folder in os.listdir(input_dir):\n",
    "    actor_path = os.path.join(input_dir, actor_folder)\n",
    "    \n",
    "    if os.path.isdir(actor_path):  \n",
    "        # Creating corresponding output directory\n",
    "        output_actor_dir = os.path.join(output_dir, actor_folder)\n",
    "        os.makedirs(output_actor_dir, exist_ok=True)\n",
    "        \n",
    "        # Processing each audio file in the actor's folder\n",
    "        for file in os.listdir(actor_path):\n",
    "            if file.endswith(\".wav\"):  \n",
    "                file_path = os.path.join(actor_path, file)\n",
    "                try:\n",
    "                    \n",
    "                    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                    # Creating a Mel spectrogram\n",
    "                    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512)\n",
    "                    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "                    # Applying noise masking\n",
    "                    spectrogram_db = apply_mask(spectrogram_db)\n",
    "\n",
    "                    # Plotting the spectrogram\n",
    "                    fig, ax = plt.subplots(figsize=(10, 10))  \n",
    "                    ax.set_axis_off()  \n",
    "                    librosa.display.specshow(spectrogram_db, sr=sr, x_axis=None, y_axis=None, cmap='gray_r', fmax=8000)\n",
    "                    plt.savefig(\"temp_spectrogram.png\", bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "                    plt.close(fig)\n",
    "\n",
    "                    # Resizing for ResNet50 (224x224)\n",
    "                    img = Image.open(\"temp_spectrogram.png\").convert(\"L\")  # Converting to greyscale\n",
    "                    img = img.resize((224, 224), Image.Resampling.LANCZOS)\n",
    "                    \n",
    "                    # Saving the spectrogram image in the corresponding output folder\n",
    "                    output_path = os.path.join(output_actor_dir, f\"{os.path.splitext(file)[0]}_spectrogram.png\")\n",
    "                    img.save(output_path)\n",
    "\n",
    "                    print(f\"Spectrogram saved: {output_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "print(\"✅ All spectrograms have been processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "folder_to_zip = \"/kaggle/working/spectrograms\"\n",
    "output_zip = \"/kaggle/working/spectrograms.zip\"\n",
    "\n",
    "shutil.make_archive(output_zip.replace(\".zip\", \"\"), 'zip', folder_to_zip)\n",
    "\n",
    "print(\"ZIP file created:\", output_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making positive and negative pairs where positive pairs correspond to audio files of the same actor and vice-versa. This has been done in order to train the model to different ways of the actor saying the same dialogue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T17:05:45.981067Z",
     "iopub.status.busy": "2025-02-07T17:05:45.980763Z",
     "iopub.status.idle": "2025-02-07T17:05:47.453427Z",
     "shell.execute_reply": "2025-02-07T17:05:47.452647Z",
     "shell.execute_reply.started": "2025-02-07T17:05:45.981046Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "\n",
    "input_dir = \"/kaggle/input/spectogramsss\"\n",
    "output_file = \"/kaggle/working/pairs.txt\"\n",
    "\n",
    "actors = [actor for actor in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, actor))]\n",
    "\n",
    "# Function to create pairs\n",
    "def create_pairs(actors, num_positive, num_negative):\n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    \n",
    "    # Creating positive pairs\n",
    "    for actor in actors:\n",
    "        actor_path = os.path.join(input_dir, actor)\n",
    "        spectrograms = [os.path.join(actor_path, file) for file in os.listdir(actor_path) if file.endswith(\".png\")]\n",
    "        if len(spectrograms) > 1:  \n",
    "            # Generating all possible pairs of spectrograms for the same actor\n",
    "            actor_pairs = list(itertools.combinations(spectrograms, 2))\n",
    "            random.shuffle(actor_pairs)\n",
    "            positive_pairs.extend(actor_pairs[:num_positive // len(actors)])  # Limit pairs per actor\n",
    "    \n",
    "    # Creating negative pairs\n",
    "    for actor1, actor2 in itertools.combinations(actors, 2):\n",
    "        actor1_path = os.path.join(input_dir, actor1)\n",
    "        actor2_path = os.path.join(input_dir, actor2)\n",
    "        spectrograms1 = [os.path.join(actor1_path, file) for file in os.listdir(actor1_path) if file.endswith(\".png\")]\n",
    "        spectrograms2 = [os.path.join(actor2_path, file) for file in os.listdir(actor2_path) if file.endswith(\".png\")]\n",
    "        if spectrograms1 and spectrograms2:\n",
    "            # Creating pairs between spectrograms of two different actors\n",
    "            negative_pairs.extend([(s1, s2) for s1 in spectrograms1 for s2 in spectrograms2])\n",
    "    \n",
    "\n",
    "    random.shuffle(negative_pairs)\n",
    "    return positive_pairs[:num_positive], negative_pairs[:num_negative]\n",
    "\n",
    "# Generating 20,000 positive and 20,000 negative pairs\n",
    "print(\"Generating pairs...\")\n",
    "positive_pairs, negative_pairs = create_pairs(actors, 20000, 20000)\n",
    "\n",
    "# Saving pairs to a file\n",
    "print(\"Saving pairs to file...\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    for pair in positive_pairs:\n",
    "        f.write(f\"{pair[0]},{pair[1]},1\\n\")  #  1 for positive\n",
    "    for pair in negative_pairs:\n",
    "        f.write(f\"{pair[0]},{pair[1]},0\\n\")  #  0 for negative\n",
    "\n",
    "print(f\"✅ Pairs saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly shuffling the contents of the pairs.txt file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T17:05:54.685401Z",
     "iopub.status.busy": "2025-02-07T17:05:54.685078Z",
     "iopub.status.idle": "2025-02-07T17:05:54.739877Z",
     "shell.execute_reply": "2025-02-07T17:05:54.738845Z",
     "shell.execute_reply.started": "2025-02-07T17:05:54.685373Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "file_path = \"/kaggle/working/pairs.txt\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Shuffling the lines\n",
    "random.shuffle(lines)\n",
    "\n",
    "# Writing the shuffled lines back to the file\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "\n",
    "print(\"File shuffled successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T17:05:59.690045Z",
     "iopub.status.busy": "2025-02-07T17:05:59.689755Z",
     "iopub.status.idle": "2025-02-07T18:35:00.685823Z",
     "shell.execute_reply": "2025-02-07T18:35:00.684881Z",
     "shell.execute_reply.started": "2025-02-07T17:05:59.690020Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import CSVLogger, Callback\n",
    "import numpy as np\n",
    "\n",
    "# Forcing GPU usage and prevent memory overflow\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✅ GPU is available and will be used.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "total_samples = 40000\n",
    "steps_per_epoch = total_samples // batch_size\n",
    "validation_samples = total_samples // 5  \n",
    "validation_steps = validation_samples // batch_size  \n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess an image given its file path.\"\"\"\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)  \n",
    "    image = tf.image.resize(image, [224, 224])  \n",
    "    image = image / 255.0  \n",
    "    return image\n",
    "\n",
    "def pair_generator(txt_file, batch_size=32, repeat=False):\n",
    "    \"\"\"\n",
    "    Generator to yield batches of image pairs and labels from a text file.\n",
    "    \"\"\"\n",
    "    while True:  \n",
    "        with open(txt_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            np.random.shuffle(lines)  # Shuffling data before each epoch\n",
    "            for i in range(0, len(lines), batch_size):\n",
    "                batch_lines = lines[i:i + batch_size]\n",
    "                images1, images2, labels = [], [], []\n",
    "                for line in batch_lines:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue  # Skipping empty lines\n",
    "                    try:\n",
    "                        file1, file2, label = line.split(\",\")\n",
    "                        images1.append(preprocess_image(file1))\n",
    "                        images2.append(preprocess_image(file2))\n",
    "                        labels.append(float(label))\n",
    "                    except ValueError:\n",
    "                        print(f\"Skipping invalid line: {line}\")\n",
    "                \n",
    "                if images1 and images2 and labels:\n",
    "                   yield (tf.convert_to_tensor(images1), tf.convert_to_tensor(images2)), tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "        if not repeat:\n",
    "            break\n",
    "\n",
    "\n",
    "txt_file_path = \"/kaggle/working/pairs.txt\"\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: pair_generator(txt_file_path, batch_size=batch_size, repeat=True),\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: pair_generator(txt_file_path, batch_size=batch_size, repeat=False),\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Defining the Siamese ResNet50 model\n",
    "base_model = ResNet50(\n",
    "    weights=\"/kaggle/input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Feature extraction for each image in the pair\n",
    "input1 = tf.keras.Input(shape=(224, 224, 3))\n",
    "input2 = tf.keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x1 = base_model(input1, training=False)\n",
    "x2 = base_model(input2, training=False)\n",
    "\n",
    "# Global average pooling\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "# Concatenating the feature vectors\n",
    "merged = tf.keras.layers.Concatenate()([x1, x2])\n",
    "\n",
    "# Fully connected layers\n",
    "dense1 = Dense(128, activation=\"relu\")(merged)\n",
    "output = Dense(1, activation=\"sigmoid\")(dense1)\n",
    "\n",
    "siamese_model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compilinng the model\n",
    "siamese_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Custom Callback to Print Metrics After Every Epoch\n",
    "class EpochLogger(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "        print(f\"  Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\")\n",
    "        print(f\"  Validation Loss: {logs['val_loss']:.4f}, Validation Accuracy: {logs['val_accuracy']:.4f}\")\n",
    "        \n",
    "        for batch in val_dataset.take(1):\n",
    "            (img1, img2), labels = batch\n",
    "            predictions = siamese_model.predict([img1, img2])\n",
    "            print(f\"  Sample True Label: {labels.numpy()[:5]}\")\n",
    "            print(f\"  Sample Predicted: {predictions[:5].flatten()}\")\n",
    "\n",
    "# Setting up CSVLogger and Custom Logger callback\n",
    "csv_logger = CSVLogger('/kaggle/working/training_log.csv', append=True)\n",
    "epoch_logger = EpochLogger()\n",
    "\n",
    "# Training the model on GPU with fixed steps per epoch\n",
    "with tf.device('/GPU:0'):\n",
    "    history = siamese_model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=steps_per_epoch,  \n",
    "        validation_steps=validation_steps,  \n",
    "        callbacks=[csv_logger, epoch_logger]\n",
    "    )\n",
    "\n",
    "\n",
    "siamese_model.save(\"/kaggle/working/siamese_model_v1.h5\")\n",
    "print(\"✅ Model training complete and saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 107620,
     "sourceId": 256618,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6602135,
     "sourceId": 10660954,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6622621,
     "sourceId": 10688768,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6623099,
     "sourceId": 10689446,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
