{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37facaec-1526-486e-ad52-e616ce5fcaa8",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. Denoising the Dataset\n",
    "2. Refining the Dataset\n",
    "   * Categorizing the dataset\n",
    "3. Augmentation of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aae593-cc98-4b92-939c-563b0b6c1b68",
   "metadata": {},
   "source": [
    "# Denoising the Dataset\n",
    "\n",
    "*Performing noise reduction on the UrbanSound8K dataset and saves the denoised audio files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e81ad-d240-48a1-a682-4f097d9abc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm  \n",
    "\n",
    "\n",
    "input_dir = \"/kaggle/input/urbansound8k\" \n",
    "output_dir = \"/kaggle/working/denoised_urbansound8k\"\n",
    "\n",
    "# Creating output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Processing each folder in the dataset\n",
    "for folder in tqdm(sorted(os.listdir(input_dir))):\n",
    "    folder_path = os.path.join(input_dir, folder)\n",
    "    \n",
    "    if os.path.isdir(folder_path):  \n",
    "        output_folder = os.path.join(output_dir, folder)\n",
    "        os.makedirs(output_folder, exist_ok=True)  \n",
    "\n",
    "        # Process each audio file in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                \n",
    "                try:\n",
    "                    # Load the audio file\n",
    "                    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                    # Estimate noise profile using the first 0.5 seconds\n",
    "                    noise_start = 0\n",
    "                    noise_end = int(sr * 0.5)  # Assume first 0.5 seconds contain noise\n",
    "                    noise_profile = y[noise_start:noise_end]\n",
    "\n",
    "                    # Applying noise reduction\n",
    "                    y_denoised = nr.reduce_noise(y=y, sr=sr, y_noise=noise_profile)\n",
    "\n",
    "                    # Saving the denoised audio\n",
    "                    output_file_path = os.path.join(output_folder, file)\n",
    "                    sf.write(output_file_path, y_denoised, sr)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "print(f\"✅ Noise reduction complete! Denoised files are saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674081bb-96c6-4b99-b041-bf5e2901b587",
   "metadata": {},
   "source": [
    "# Refining the Dataset\n",
    "\n",
    "*Processing denoised UrbanSound8K audio files to generate Mel spectrograms and save them as **grayscale images (224x224) and masking them** for use in models like ResNet50.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c5a16-0ab5-42aa-b8d4-bde4a7b018f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the denoised audio folder\n",
    "print(\"Started\")\n",
    "input_dir = \"/kaggle/working/denoised_urbansound8k\"\n",
    "output_dir = \"/kaggle/working/spectrograms\"\n",
    "\n",
    "# Creating the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to apply noise masking (cropping axes)\n",
    "def apply_mask(spectrogram_db):\n",
    "    threshold = np.percentile(spectrogram_db, 5)  # Remove lowest 5% intensity values\n",
    "    spectrogram_db[spectrogram_db < threshold] = np.min(spectrogram_db)\n",
    "    return spectrogram_db\n",
    "\n",
    "# Target from fold1->fold10\n",
    "for i in range(1,11):  \n",
    "    folder = f'fold{i}'\n",
    "    folder_path = os.path.join(input_dir, folder)\n",
    "\n",
    "    if os.path.isdir(folder_path):  \n",
    "        output_folder = os.path.join(output_dir, folder)\n",
    "        os.makedirs(output_folder, exist_ok=True)  \n",
    "\n",
    "        # Process each audio file in the folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                try:\n",
    "                    # Loading the audio file\n",
    "                    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                    # Creating a Mel spectrogram\n",
    "                    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512)\n",
    "                    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "                    # Applying noise masking\n",
    "                    spectrogram_db = apply_mask(spectrogram_db)\n",
    "\n",
    "                    # Ploting the spectrogram\n",
    "                    fig, ax = plt.subplots(figsize=(10, 10))  # Square size for ResNet\n",
    "                    ax.set_axis_off()  # Remove axes\n",
    "                    librosa.display.specshow(spectrogram_db, sr=sr, x_axis=None, y_axis=None, cmap='gray_r', fmax=8000)\n",
    "                    plt.savefig(\"temp_spectrogram.png\", bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "                    plt.close(fig)\n",
    "\n",
    "                    # Resizing for ResNet50 (224x224)\n",
    "                    img = Image.open(\"temp_spectrogram.png\").convert(\"L\")  # Convert to greyscale\n",
    "                    img = img.resize((224, 224), Image.Resampling.LANCZOS)  # Use LANCZOS for resampling\n",
    "                    output_path = os.path.join(output_folder, f\"{os.path.splitext(file)[0]}_spectrogram.png\")\n",
    "                    img.save(output_path)\n",
    "\n",
    "                    print(f\"Spectrogram saved: {output_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "print(\"✅ All spectrograms in fold have been processed and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed97b49-7c00-4b32-8b5a-81a674ffa734",
   "metadata": {},
   "source": [
    "# Categorizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e2478-6b58-45c2-a5c9-42d434d9ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the DataFrame with class information\n",
    "csv_file = \"/kaggle/input/urbansound8k/UrbanSound8K.csv\" \n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "df['slice_prefix'] = df['slice_file_name'].str.replace('.wav', '', regex=False)\n",
    "\n",
    "# targeting folders (1to 10 inclusive)\n",
    "for i in range(1, 11):\n",
    "    # Define the folder path for the current fold\n",
    "    image_folder = f\"/kaggle/working/spectrograms/fold{i}\"  \n",
    "    \n",
    "    # Checking if the image folder exists\n",
    "    if not os.path.exists(image_folder):\n",
    "        print(f\"Image folder not found: {image_folder}\")\n",
    "        continue\n",
    "\n",
    "    # Output folder for sorted images\n",
    "    output_folder = \"/kaggle/working/sorted_images/folder1\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Loop through each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        base_name = row['slice_prefix'] \n",
    "        class_label = row['class']       \n",
    "\n",
    "        # Finding the corresponding image file in the folder\n",
    "        for file in os.listdir(image_folder):\n",
    "            if file.startswith(base_name):\n",
    "                image_path = os.path.join(image_folder, file)\n",
    "\n",
    "             \n",
    "                class_folder = os.path.join(output_folder, class_label)\n",
    "                os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "                # Copying the image to the corresponding class folder\n",
    "                shutil.copy(image_path, os.path.join(class_folder, file))\n",
    "                print(f\"Copied {file} to {class_folder}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"No matching image found for {base_name}\")\n",
    "\n",
    "print(\"Relabeling and sorting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f855578-3da9-4d21-aa72-279d95fd73a8",
   "metadata": {},
   "source": [
    "# Augmentation of Dataset\n",
    "\n",
    "*For increasing the number of data items, we are augmenting our dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e6c16-06ae-4152-986f-6f471fbf617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(\"started\")\n",
    "input_dir = \"/kaggle/working/sorted_images/folder1\"\n",
    "augmented_dir = \"/kaggle/working/augmented_spectrograms\"\n",
    "\n",
    "# Creating the augmented directory if it doesn't exist\n",
    "os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "# Function to apply time shifting\n",
    "def time_shift(img, max_shift=5):\n",
    "    shift = random.randint(-max_shift, max_shift)\n",
    "    return np.roll(img, shift, axis=1)  # Shift along the horizontal axis (time)\n",
    "\n",
    "# Function to apply frequency shifting (along vertical axis)\n",
    "def frequency_shift(img, max_shift=5):\n",
    "    shift = random.randint(-max_shift, max_shift)\n",
    "    return np.roll(img, shift, axis=0)  # Shift along the vertical axis (frequency)\n",
    "\n",
    "# Function to apply random cropping\n",
    "def random_crop(img, crop_size=(180, 180)):\n",
    "    height, width = img.shape\n",
    "    crop_height, crop_width = crop_size\n",
    "    top = random.randint(0, height - crop_height)\n",
    "    left = random.randint(0, width - crop_width)\n",
    "    return img[top:top+crop_height, left:left+crop_width]\n",
    "\n",
    "# Function to add random noise\n",
    "def add_noise(img, noise_factor=0.1):\n",
    "    noise = np.random.randn(*img.shape) * noise_factor\n",
    "    img = img + noise\n",
    "    img = np.clip(img, 0., 1.)  # Clip to [0, 1] to avoid overflow\n",
    "    return img\n",
    "\n",
    "# Function to augment and save the images\n",
    "def augment_images():\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        \n",
    "        if os.path.isdir(class_path):\n",
    "            # Create the corresponding folder in the augmented directory\n",
    "            augmented_class_path = os.path.join(augmented_dir, class_name)\n",
    "            os.makedirs(augmented_class_path, exist_ok=True)\n",
    "\n",
    "            # Process each image in the class folder\n",
    "            for image_name in os.listdir(class_path):\n",
    "                if image_name.endswith('.png'):\n",
    "                    image_path = os.path.join(class_path, image_name)\n",
    "                    img = Image.open(image_path).convert(\"L\")  # Open as grayscale\n",
    "                    img = np.array(img) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "                    # Apply augmentations\n",
    "                    augmented_images = []\n",
    "                    augmented_images.append(img)  # Keep original image\n",
    "\n",
    "                    # Time shift\n",
    "                    augmented_images.append(time_shift(img))\n",
    "                    # Frequency shift\n",
    "                    augmented_images.append(frequency_shift(img))\n",
    "                    # Random crop\n",
    "                    augmented_images.append(random_crop(img))\n",
    "                    # Add noise\n",
    "                    augmented_images.append(add_noise(img))\n",
    "\n",
    "                    # Save augmented images\n",
    "                    for idx, augmented_img in enumerate(augmented_images):\n",
    "                        augmented_img = (augmented_img * 255).astype(np.uint8)  # Denormalize to [0, 255]\n",
    "                        augmented_img_pil = Image.fromarray(augmented_img)\n",
    "                        augmented_img_pil.save(os.path.join(augmented_class_path, f\"{os.path.splitext(image_name)[0]}_aug{idx}.png\"))\n",
    "\n",
    "                    print(f\"Augmented images for {image_name} saved in {augmented_class_path}\")\n",
    "\n",
    "    print(\"✅ Augmentation completed.\")\n",
    "\n",
    "augment_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
