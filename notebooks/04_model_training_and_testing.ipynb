{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fb0334-97fa-4677-bedc-b42108037a69",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. Training the Model\n",
    "   * Version 1\n",
    "   * Version 2\n",
    "   * Version 3 (With augmentation)\n",
    "2. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6c986-0484-4eef-915a-350c6ce589c8",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32ed10-180f-40a6-bd8a-a677445e11f8",
   "metadata": {},
   "source": [
    "**Version 1**\n",
    "\n",
    "**Now training the model with denoised dataset,grayscale,masking and 10 epoch cycles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e489578-dfa3-420f-96f5-65302c095e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Step 1: Load and preprocess the dataset\n",
    "dataset_path = \"/kaggle/working/sorted_images/folder1\" \n",
    "\n",
    "# Load dataset (training and validation split)\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),  # ResNet input size\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Access class names from the original dataset object\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Normalize pixel values (Min-Max Scaling)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Step 2: Define the ResNet50 model\n",
    "base_model = ResNet50(\n",
    "    weights=\"/kaggle/input/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\", \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
    "x = Dense(128, activation=\"relu\")(x)  # Add a dense layer\n",
    "predictions = Dense(len(class_names), activation=\"softmax\")(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers (optional)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "# Step 7: Save the final model\n",
    "model.save(\"/kaggle/working/version1.h5\")  # Use .keras extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd222e-3aea-44a0-b041-f51465fd1dd5",
   "metadata": {},
   "source": [
    "**Version 2**\n",
    "\n",
    "**Again training the model but now with 20 epoch cycles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cde10c-bbbc-47a7-a074-97b97680a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Step 1: Load and preprocess the dataset\n",
    "dataset_path = \"/kaggle/working/sorted_images/folder1\"  \n",
    "\n",
    "# Load dataset (training and validation split)\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),  # ResNet input size\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Access class names from the original dataset object\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Normalize pixel values (Min-Max Scaling)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Step 2: Define the ResNet50 model\n",
    "base_model = ResNet50(\n",
    "    weights=\"/kaggle/input/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\", \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
    "x = Dense(128, activation=\"relu\")(x)  # Add a dense layer\n",
    "predictions = Dense(len(class_names), activation=\"softmax\")(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers (optional)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "# Step 7: Save the final model\n",
    "model.save(\"/kaggle/working/version2.h5\")  # Use .keras extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824c342-e6ef-43b7-9e11-99ce3e3d122e",
   "metadata": {},
   "source": [
    "**Version 3**\n",
    "\n",
    "**Again, training the model but now with augmented dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaba8af-fc0b-44a3-9770-ea593f0145c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import CSVLogger  # Import CSVLogger\n",
    "\n",
    "# Step 1: Load and preprocess the dataset\n",
    "dataset_path = \"/kaggle/working/augmented_spectrograms\"\n",
    "\n",
    "# Load dataset (training and validation split)\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224), \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Access class names from the original dataset object\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Normalize pixel values (Min-Max Scaling)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Step 2: Define the ResNet50 model\n",
    "base_model = ResNet50(\n",
    "    weights=\"/kaggle/input/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\", \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
    "x = Dense(128, activation=\"relu\")(x)  # Add a dense layer\n",
    "predictions = Dense(len(class_names), activation=\"softmax\")(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers (optional)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Step 4: Set up CSVLogger callback\n",
    "csv_logger = CSVLogger('/kaggle/working/training_log.csv', append=True)\n",
    "\n",
    "# Step 5: Train the model with CSVLogger callback\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[csv_logger]  # Add the callback here\n",
    ")\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Step 7: Save the final model\n",
    "model.save(\"/kaggle/working/version3.h5\")  # Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd42fa9-ae64-4dd9-ad36-d3bdb8a79761",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7563e-f307-4c86-82f7-dae2a8f6c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Loading the models\n",
    "model1 = tf.keras.models.load_model(\"/kaggle/input/version1/keras/basic/1/version1.h5\")\n",
    "model2 = tf.keras.models.load_model(\"/kaggle/input/version1/keras/basic/1/version1.h5\")\n",
    "model3 = tf.keras.models.load_model(\"/kaggle/input/version3/keras/advanced/1/version3.h5\")\n",
    "\n",
    "# saving them in working directory\n",
    "model1.save(\"/kaggle/working/converted_model1.h5\")\n",
    "model2.save(\"/kaggle/working/converted_model2.h5\")\n",
    "model3.save(\"/kaggle/working/converted_model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea918c-b99d-45c5-ad3c-d2b2c9517be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "\n",
    "# Loading the trained model\n",
    "model_path1 = \"/kaggle/working/converted_model1.h5\"\n",
    "model1 = tf.keras.models.load_model(model_path1)\n",
    "\n",
    "model_path2 = \"/kaggle/working/converted_model2.h5\"\n",
    "model2 = tf.keras.models.load_model(model_path2)\n",
    "\n",
    "model_path3 = \"/kaggle/working/converted_model3.h5\"\n",
    "model3 = tf.keras.models.load_model(model_path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87928723-e48b-419e-96e0-499afb18d58a",
   "metadata": {},
   "source": [
    "**Via Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499422c9-9f07-4233-8646-33821a15e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class_labels = [\n",
    "    \"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\", \"Class 4\",\n",
    "    \"Class 5\", \"Class 6\", \"Class 7\", \"Class 8\", \"Class 9\"\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # Convert grayscale to RGB\n",
    "    img = img.resize((224, 224))  # Resize to 224x224\n",
    "    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array.astype(\"float32\")\n",
    "\n",
    "\n",
    "image_path = \"/kaggle/input/testing/101415-3-0-3_spectrogram.png\"\n",
    "processed_image = preprocess_image(image_path)\n",
    "\n",
    "# Load trained models\n",
    "model1 = tf.keras.models.load_model(\"/kaggle/working/converted_model1.h5\")\n",
    "model2 = tf.keras.models.load_model(\"/kaggle/working/converted_model2.h5\")\n",
    "model3 = tf.keras.models.load_model(\"/kaggle/working/converted_model3.h5\")\n",
    "\n",
    "# Function to get predicted class name\n",
    "def get_class_name(predictions):\n",
    "    predicted_class = np.argmax(predictions)  # Get index of max probability\n",
    "    return class_labels[predicted_class]  # Get class name\n",
    "\n",
    "# Predictions for each model\n",
    "predictions1 = model1.predict(processed_image)\n",
    "print(f\"Predicted class for model 1: {get_class_name(predictions1)}\")\n",
    "\n",
    "predictions2 = model2.predict(processed_image)\n",
    "print(f\"Predicted class for model 2: {get_class_name(predictions2)}\")\n",
    "\n",
    "predictions3 = model3.predict(processed_image)\n",
    "print(f\"Predicted class for model 3: {get_class_name(predictions3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d1806-66ed-4d00-81e4-b13241c3fe9e",
   "metadata": {},
   "source": [
    "**Via Sounds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f52e0-b46b-4418-8158-090f0442e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import noisereduce as nr\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define class labels\n",
    "class_labels = [\n",
    "    \"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\", \"Class 4\",\n",
    "    \"Class 5\", \"Class 6\", \"Class 7\", \"Class 8\", \"Class 9\"\n",
    "]\n",
    "\n",
    "# Function to apply noise masking\n",
    "def apply_mask(spectrogram_db, threshold=-40):\n",
    "    \"\"\" Masks low-intensity regions of the spectrogram. \"\"\"\n",
    "    return np.where(spectrogram_db < threshold, np.min(spectrogram_db), spectrogram_db)\n",
    "\n",
    "# Function to generate Mel spectrogram\n",
    "def generate_spectrogram(file_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Apply noise reduction\n",
    "    y_denoised = nr.reduce_noise(y=y, sr=sr)\n",
    "\n",
    "    # Generate Mel spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y_denoised, sr=sr, n_fft=2048, hop_length=512)\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "    # Apply noise masking\n",
    "    spectrogram_db = apply_mask(spectrogram_db)\n",
    "\n",
    "    # Plot the spectrogram\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))  # Square size for ResNet\n",
    "    ax.set_axis_off()\n",
    "    librosa.display.specshow(spectrogram_db, sr=sr, cmap=\"gray_r\", fmax=8000)\n",
    "\n",
    "    # Save temp spectrogram\n",
    "    temp_path = \"temp_spectrogram.png\"\n",
    "    plt.savefig(temp_path, bbox_inches=\"tight\", pad_inches=0, dpi=100)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Resize for ResNet50 (224x224)\n",
    "    img = Image.open(temp_path).convert(\"L\")  # Convert to grayscale\n",
    "    img = img.resize((224, 224), Image.Resampling.LANCZOS)  # Use LANCZOS resampling\n",
    "    final_path = \"final_spectrogram.png\"\n",
    "    img.save(final_path)\n",
    "\n",
    "    return final_path  # Return final spectrogram path\n",
    "\n",
    "# Function to preprocess the image for model input\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # Convert grayscale to RGB\n",
    "    img = img.resize((224, 224))  # Resize to 224x224\n",
    "    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array.astype(\"float32\")\n",
    "\n",
    "# Load trained models\n",
    "model1 = tf.keras.models.load_model(\"/kaggle/working/converted_model1.h5\")\n",
    "model2 = tf.keras.models.load_model(\"/kaggle/working/converted_model2.h5\")\n",
    "model3 = tf.keras.models.load_model(\"/kaggle/working/converted_model3.h5\")\n",
    "\n",
    "# Function to get predicted class name\n",
    "def get_class_name(predictions):\n",
    "    predicted_class = np.argmax(predictions)  # Get index of max probability\n",
    "    return class_labels[predicted_class]  # Get class name\n",
    "\n",
    "# Path to the input audio file\n",
    "audio_path = \"/kaggle/input/testing/sample_audio.wav\"\n",
    "\n",
    "# Generate spectrogram\n",
    "spectrogram_path = generate_spectrogram(audio_path)\n",
    "\n",
    "# Preprocess image for model\n",
    "processed_image = preprocess_image(spectrogram_path)\n",
    "\n",
    "# Make predictions using all models\n",
    "predictions1 = model1.predict(processed_image)\n",
    "print(f\"Predicted class for model 1: {get_class_name(predictions1)}\")\n",
    "\n",
    "predictions2 = model2.predict(processed_image)\n",
    "print(f\"Predicted class for model 2: {get_class_name(predictions2)}\")\n",
    "\n",
    "predictions3 = model3.predict(processed_image)\n",
    "print(f\"Predicted class for model 3: {get_class_name(predictions3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
